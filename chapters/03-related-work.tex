\chapter{Related Work}
\label{chapter:related-work}

In this chapter, we review the state-of-the-art of group interactions between humans and robots. We identified four main topics among the reviewed literature, which constitute the first four sections of the current chapter. The last section contributes with a comparative analysis and an overview of the expected contributions of this dissertation.



\section{Group Identity, Membership and Social Categorisation}
\label{sec:identity}
Group identity is one of the most fundamental aspects of a group as it defines its formation and membership. In other words, it is responsible for the categorisation of individuals as part of a larger identity or group. Group identification is also associated with many group processes and, therefore, researchers interested in human-robot group interaction have been playing close attention to it.

Eyssel \& Kuchenbrandt pioneered the exploration of social categorisation in HRI. They manipulated social categorisation with the background information of the robot, i.e., nationality and name \cite{eyssel2012social}. Participants reported their perceptions of the robot after seeing a picture of it. The salience of that group membership was enough for participants to rate the ingroup robot more favourably and anthropomorphise it more.

In a similar experiment, Kuchenbrandt et al. manipulated group identity by simply associating colours to two groups, the minimal-group paradigm, and the robot would either be from the ingroup or the outgroup \cite{kuchenbrandt2013robot}. Participants were greeted with a short introduction by the robot and then rated their perceptions of it. Participants that interacted with the ingroup robot attributed significantly more anthropomorphism to it and even revealed higher willingness to interact with robots in general, compared to the ones that interacted with the outgroup robot.

One of the experiments presented by Deligianis et al. also explored the minimal group paradigm by simply priming participants about a presumed ``robot condition'' or a ``computer condition'' \cite{deligianis2017impact}. Participants had to play the shell game in a team with a robot that occasionally disagreed with the participant's answer to measure trust or compliance with that suggestion. Moreover, the difficulty of the game was manipulated in two levels, medium and hard. The results confirmed their first hypothesis stating that participants would trust the robot more often when the game difficulty was harder. Regarding the manipulation of the ingroup, it influenced the proxemics between the participants and the robot after the game, but no significant differences were found in trust to comply with the robot's suggestions.

The minimal group paradigm has not been always successful to induce the group membership. Sembroski et al. run a user study with a medical diagnosis task in which the robot would either be presented as a teammate (ingroup) or as a provider of additional information (outgroup) \cite{sembroski2017he}. The goal of this user study was to analyse participants' willingness to follow the robot's instructions. Nevertheless, the manipulation check of group membership did not reveal significant differences between these two experimental groups suggesting the nature of the task might have conditioned this perception.


Recently, Steain et al. presented the results of a user study where they have analysed social categorisation in the shell game \cite{steain2019black}. The manipulation of identity was achieved by introducing the robots as ``EngBot'' and ``PsycBot'' to a population of students from psychology. The results of the experiment were focused on the perceptions of the robots and the degree of compliance with the answers of each robot i.e., trust. Although no significant differences were found for trust, participants rated the ingroup robot more favourably, kept a closer distance and preferred it more compared to the outgroup robot.


The identification towards a certain group can emerge from social aspects, as well as task-related aspects. As a result, several group identities can be present at the same time. In light of this idea, Haring et al. explored both task structure i.e., robotic partner or competitor, and the social membership, manipulated by the nationality of the robots \cite{haring2014would}. In their user study, participants had to play a card game with two robots, where one of them was their teammate and the other was their opponent. Participants were told each robot was developed by a team of either their own nationality (ingroup) or another one (outgroup) and the names of the robots would also match their alleged nationality. The two experimental conditions mapped the congruency between social membership of the robots and their role in the game: ingroup partner and outgroup opponent; and outgroup partner and ingroup opponent. Results identified a main effect of the social membership on the perception of competence and on the cooperation index, with participants rating the ingroup robot as more competent and cooperated more with it compared to the outgroup robot. A surprising result of this user study was the fact that participants reported higher closeness to the ingroup robot when it was their partner compared to when it was their opponent but no similar difference occurred for the outgroup robot.


Finally, Fraune et al. presented the results of a user study whose goal was to compare the membership towards humans and robots. In their experiment, two teams of two people and two robots each had to competitively play a price-guessing game \cite{fraune2017teammates}. The main goal of this user study was to compare the perception and behaviour towards the ingroup and outgroup members, which was inherently set by the competitive setting. Additionally, it explored differences between robotic and human members. The results in terms of anthropomorphism and perceptions of cooperation support a strong impact of the ingroup setting compared to the outgroup, regardless of being a robot or a human. However, there was a surprising interaction effect on the aggression measure which was a noise blast that participants could use to damage partners or opponents during the game. Participants favoured the ingroup human over the ingroup robots, but they also favoured ingroup robots over outgroup humans. To a certain extent, this result indicates that people can favour robots over humans in some competitive settings.



\section{Group Phenomena in HRI}
\label{sec:phenomena}
Another line of research that we identified in the literature of human-robot group interactions is a set of user studies trying to verify if well-known group phenomena from the social sciences also applies to HRI. Therefore, the commonality among the following user studies is a comparison between individuals and groups of humans interacting with robot(s).

Chang et al. examined if the discontinuity effect translates into human-robot interactions \cite{chang2012effect}. This effect suggests that interactions among groups of humans are more competitive than interactions among individuals. The user study manipulated the number of people in one team (either 1 or 2) and the number of robots in the adversarial team (also either 1 or 2). The interaction consisted of a board game with occasional social dilemmas between the teams to measure competitiveness. The results do not fully support the discontinuity effect in HRI but only than increasing the number of people increases competitiveness.

In a similar experiment, Fraune et al. have also analysed the discontinuity effect \cite{fraune2019human}. Participants, individually or in a group of three, engaged in a social dilemma against a either a single robot or a group of three robots. The goal of this user study was to analyse the perceptions of the participants, as well as their competitiveness, in each of four experimental conditions. Contrary to human-human interaction, where increasing the number of members in at least one group would increase competitiveness, the results of this user study suggest a different pattern in human-robot interaction. In the two conditions where both teams had the same size, individual vs. individual and group vs. group, the competitiveness was higher. Additional results revealed that participants that played in groups of three had more negative emotions and competed more with the robot(s), compared to participants playing individually. Moreover, they found a positive correlation between the entitativity of the human group and the competitiveness, and also between the entitativity of the robot group and the reported fear.

Another interesting group phenomenon is comformity, which occurs in group interactions when a member changes his opinion or action in order to increase the consistency with other group members. This phenomenon illustrates how group processes may go beyond individual processes and how complex group interactions can be. Brandstetter et al. investigated if robots were also able to produce conformity behaviours in humans \cite{brandstetter2014peer}. In their experiment, a group of 5 people was compared to a group of one person and four robots. The task was a linguistic quiz to identify past tenses. Although participants exhibited conformity with human peers, they did not display with the robots.

Solomons et al. have also explored conformity effect within a group of a human and three robots playing the Dixit game \cite{salomons2018humans}. In their modified version of the game, a fourth robot was always the game master and would say a new word every round for the players to guess the corresponding card. There were two conditions: one where the participant could see which card was voted by the other robots and change his original decision; and a control condition in which the participant could not see the decisions of the robotic players. The results suggested that people have indeed conformed with the robots' responses in the experimental group. Additionally, the authors discussed a possible explanation for the incongruent result with Brandstetter et al. related to trust. They postulated trust plays an important role to perform conformity behaviours as robot started to choose incorrect answers and participants stopped conforming later in the game.

Interpersonal groups can outperform individuals in a variety of tasks and can, sometimes, even display higher learning gains. In order to explore this idea, Leite et al. have examined a learning activity between children and robots in an interactive storytelling scenario \cite{leite2015emotional}. In particular, they have compared a single child with a group of three children in terms of story recall and the emotional interpretation of the story content. The results revealed that participants interacting alone presented higher levels of recall, compared to participants in the group condition. The authors speculated some possible reasons, for instance, group interaction may require children to work on their social standing, which may have compromised their attention.

Finally, a recent in-the-wild experiment revealed several human factors affecting human-robot interactions, including the number of people within the group \cite{fraune2019humangroup}. In this user study, Robovie was deployed in a Japonese shopping mall with the purpose of giving directions to people. Video recordings of 2714 participants and surveys responses of 78 participants were collected and extensively analysed. The results showed that people interacting with the robot in groups, especially the entitative groups, (1) interacted more and for longer periods, (2) behaved more socially towards the robot, and (3) were more positive, compared to people interacting alone. Additionally, people in groups displayed compliance with social norms of the group, for instance, when someone in the group interacted with the robot, the others were likely to interact as well.



\section{Perceptions of Groups of Robots}
\label{sec:perceptions}
Robots may be required to perform or execute tasks in groups without human intervention or collaboration. Nevertheless, they will certainly be deployed in social settings and be surrounded by humans, whose perceptions and expectations might constrain their behaviour. As a result, this section overviews research on how people react to and perceive groups of robots. 

Admoni et al. analysed different conformity levels in groups of robots and how they impact the perceptions of humans \cite{admoni2013dancing}. Participants saw videos of robots performing a dance routine where one of them was dancing independently while the others were coordinated and synchronised. They manipulated the size of the group to have either four or eight robots in order to increase the sense of majority and minority (3+1 and 7+1). Additionally, there was a control condition with only two robots with opposing dances. The dance type was also manipulated so that the minority robot could be dancing unique and distinct dance moves, similar moves but in a difference order, following the exact same moves but behind time, or leading the exact same moves ahead of time. Results showed the minority robot was consistently rated as less of a team-player and more anti-social, but more creative as well. This team-player measure was exacerbated when the group size increased. However, the differences across the four dance types were not statistically significant.

Behavioural mimicry was also analysed with other two factors, appearance and eye gaze, by Nawroj and collaborators \cite{nawroj2014exploration}. Participants of the user study saw videos of three robots performing a dancing routine (robots A, B and C) and were only asked to rate the groupiness of robot C. The mimicry variable was manipulated for the robot C to either mimic A, B or none. Similarly, appearance and gaze were also manipulated for the robot C to either look like and gaze at A, B or none. As a result, there were 27 different videos of the robots dancing and each participant saw and rate nine of them. The results highlighted a strong main effect of behavioural mimicry, even when it interacted with conflicting cues from the appearance and gaze. Additionally, there was also a main effect of the appearance variable while mutual-gaze was not a significant predictor of grouping patterns.

Fraune \& {\v{S}}abanovi{\'c} explored the perceptions of people towards a group of three robotic vacuum cleaners \cite{fraune2014negative}. The user study manipulated in a between-subjects design the communication style among the robots, which could either be silent, loud, or no communication at all. The results revealed no significant differences between the attitudes towards robots, as well as on the perceived social attributes o the robots. Moreover, in the manipulation check questions, participants could not identify differences in the communication style of the robots. The authors speculate that the non-humanoid embodiment of the Roomba as well as the low sociability of the robots might have strongly influenced the lack of differences.

Later, the same authors and collaborators investigated the role of embodiment when comparing a single robot with a group of robots \cite{fraune2015rabble}. They run a user study in which videos of the robots were shown to people and their perceptions were assessed in subjective questionnaires. In a between-subjects design, the video displayed either a single robot or a group, which could in turn have a humanoid embodiment (NAO), zoomorphic (Pleo) or mechanomorphic (Roomba). The results revealed an interaction effect between the two variables, group size and embodiment type. Groups of Roomba robots increased the negative responses, such as threat, anxiety or fear, compared to a single Roomba robot. On the other hand, The groups of NAO robots were positively rated in terms of elicited affect, perceived threat and trust, compared to a single NAO robot. Finally, the comparison between a single Pleo and the group of Pleo robots did not reveal differences in affective states but rather in the description traits (i.e., stereotypes) and future work contexts.

In their demand to understand the factors influencing the perceptions of robots in groups, Fraune and collaborators conducted another experiment where sociable trash robot entered the a public space, the cafeteria of the university \cite{fraune2015three}. They assessed behavioural and subjective measures of participants interacting with the robots and manipulated the number of robots, either one or a group of three, and different robotic behaviours, social or functional. The social behaviours consisted of contingent behaviour towards participants, such as greeting with a bow or a nod and a nonverbal ``thank you'' for throwing trash. A main effect of the number of robots revealed that a group of robots induced more direct interaction and more trash being thrown. Similarly, the main effect of the behaviour also shown that functional behavioural elicited longer gazes by people and more trash being thrown. Overall people preferred single social robots and groups of functional robots.

Finally, the last contribution of Fraune and collaborators to this line of research includes an experiment on the impact of group entativity \cite{fraune2017threatening}. Participants engaged in an object-matching task and the robot, or group of robots (depending on the condition), would assert their ability to perform the task. There were three conditions: a single robot, an entitative group and a diverse group. Entitativity was manipulated by the appearance, motion, proximity and decisions of the robots. The entitative group was perceived as more threatening than both the diverse group and the single robots. Moreover, the entitative group was also perceived more negatively when compared to the single robots only. On the other hand, participants attributed more mind to the diverse group than single robots.



\section{Robotic Group Behaviour}
\label{sec:behaviour}
Providing autonomy to social robots in group interactions can be a challenging task as it may include perceptive, cognitive and decision-making capabilities. The findings of the following reviewed papers contribute to the scope of literature that understands how robots can perceive and act in group settings with humans.

Leite et al. have contributed to enhancement of robotic perceptions in group interactions \cite{leite2015comparing}. The authors collected data of children playing an interactive storytelling activity with two robots in two distinct conditions: one where children participated alone and another where children participated in groups of three. Then, they developed two predictive models of individual disengagement, one trained with data from single interaction condition and another from group interaction condition. The annotations of engagement were done by human coders. Their analysis is focused on the evaluation of the two predictive models in both datasets in order to investigate how well the model trained on single interaction performs in group interaction and vice-versa. The disengagement model trained from group interactions performed reasonably well in the single interaction dataset, while the opposite could not be validated.

Jung et al. explored backchanneling behaviour in human-robot teamwork \cite{jung2013engaging}. They run a user study where a team of 5 members (3 robots, 1 participant and 1 human confederate) had to retrieve items from a building that has allegedly collapsed. In a between-subjects design, they manipulated both the presence of backchanneling behaviour and the task complexity. Results showed that when robots employed the backchanneling behaviour, they were perceived as more engaged to the task and their human partners reported lower stress levels as well as lower cognitive load, especially for the complex task. However, the backchanneling behaviour decreased the perception of competence of the robots. Overall, it seems that backchanneling can positively influence human-robot teamwork at a certain cost, and it is mostly beneficial in complex or demanding task.

Another sort of nonverbal behaviour was also explored by VÃ¡zquez et al. that examined how a robot is perceived during a group conversation according to its body orientation and gaze direction \cite{vazquez2017towards}. They run a user study in which groups of three participants had to brainstorm about possible tasks or purposes for the robot. Participants were briefed and debriefed by the robot and during the group discussion, it pretended to be listening and paying attention to conversation. Both the orientation and gaze of robot were manipulated in a between-subjects design. Orientation could be towards the middle of the conversation group or towards the participant that had the conversational floor, while gaze could be random or also attentive towards the participant that had the conversational floor. Although participants in the four experimental groups reported similar feelings of inclusion and belonging to the group, the gaze affected participants' perception of the robot motion, as well as the orientation affected the perception of its gaze. These results suggest gaze and orientation should be jointly design and controlled.

Conflict is believed to be an important stage of group development \cite{forsyth1990group} and the resolution of conflict is associated with several measures of group performance \cite{jung2016coupling}. Recently, Jung et al. have looked at how the emotional behaviour of a robot can have a positive impact on improving teamwork by employing emotion regulation strategies to diffuse conflict situations \cite{Jung2015}. The results suggested that although the robot's repair interventions have increased the groups' awareness of conflict, they can aid the conflict regulating process of the team.

Similarly, Shen et al. analysed the impact of a robotic mediator during conflict resolution among children \cite{shen2018stop}. In their experiment, pairs of children played five activities during 50 minutes that were facilitated by the robot. In a between-subjects design, they manipulated whether the robot would or not display an additional conflict mediation when children engaged in object possession conflicts. The procedure for the robot to intervene consisted of three steps: (1) play a whilst sound and identify the conflict; (2) offer prompts for constructive conflict resolution; and (3) wrap up and move forwards from the conflict. Results have shown that children were more likely to solve the conflicts constructively in the condition where the robot mediated the conflicts compared to the control condition.

Social robots can have different roles in the the way they interact with humans, from partners to opponents, or even have mixed-motive goals to mere facilitators or mediators. Tennent et al. have recently investigated whether a peripheral robotic microphone can positively shape the interpersonal dynamics of a team during a problem solving task \cite{tennent2019micbot}. They run a user study in which the robot displayed one of three possible behaviours: no movement, random, and engagement. The engagement behaviour balanced between following who had the conversational floor and encouraging the participant who had spoke the least. Results showed that in the engagement condition, the conversational dynamics was more even compared to the no movement. Curiously, there were no significant differences between the random condition and the engagement, nor between the random and no movement. This suggest the behaviour of the robot might have to be somehow socially contingent in order to differ from the stationary robot. Additionally, they found a correlation between the unevenness measure and team performance. Overall, the engagement behaviour produced more balanced discussions among the team and led to better team performance.

Finally, another work explored a mediation role by a social robot that was assisting a team of two humans in a tower construction task. In particular, Jung et al. examined different resource allocation algorithms and their impact on the task execution \cite{jung2018robot}. In their user study, the robot could either equally distribute the blocks among the two team members or execute an unequal distribution by giving 65\% of the blocks to one participant and 35\% to the other. The results revealed that team members in equal distribution reported a significantly more positive interpersonal relationship than team members in the unequal distribution condition.



\subsection{Analysis of Human-Robot Group Interaction}
The scope of papers we have reviewed highlights a diversity of topics within human-robot group interaction. Beyond the categorisation we have created in the previous sections, there are other interesting ways to analyse group interactions regarding the type of tasks involved, the structure of the group itself, and the role of the robot(s).

In order to perform such comparison, we have used the circumplex of group tasks proposed by McGrath \cite{mcgrath1995methodology}, see Figure~\ref{fig:circumplex}. This model for classifying group tasks has eight octants along the two dimensions of \textit{generate-negotiate} and \textit{choose-execute}. In the generate quadrant, tasks can either be \textit{creative} if the goal is to generate ideas, or of \textit{planning} type if the goal is to elaborate a plan. In the choose quadrant, the task is to solve a problem that can either have, or not have, correct answers, \textit{intellective} or \textit{decision making}, respectively. In the negotiate quadrant, the tasks require conflict resolution and the octants depend on the nature of the conflict. It is a \textit{cognitive conflict} in case of conflicting viewpoints and it is considered a \textit{mixed motive} in case of conflicting interests. Finally, in the execute quadrant, tasks can either be \textit{competitions} or of \textit{performance} type if it involves resolving conflicts of power or execute a performance or psychomotor task, respectively.

\begin{figure}
    \centering
    \input{images/related-work/circumplex.tex}
    \caption{Reviewed papers in the Circumplex of Group Tasks \cite{mcgrath1995methodology}}
    \label{fig:circumplex}
\end{figure}

Most of the works exploring group identity and group membership (blue references in Figure~\ref{fig:circumplex}) are located in the \textit{choose} quadrant, revealing the nature of those tasks requires people to perform some kind of decision. The manipulations of group identity or the simple social categorisations were achieved by either the minimal group paradigm or by the structure of the group, i.e., people forming teams with the robots. Additionally, we also noticed that the most common role for the robot(s) in this set of papers is the being a peer or a teammate. Consequently, the predominant structure or composition of these groups is human-robot mixed groups.

The second group of papers we have analysed (violet references in Figure~\ref{fig:circumplex}) corresponds to the exploration of group phenomena in HRI. There is no predominant type of task among the reviewed papers. Nevertheless, there seems to be a tendency to explore the role of a competitor. Most of the discussed scenarios attributed similar goals to both humans and robots in a way that they compete for resources either implicit- or explicitly.

Regarding the perceptions of groups of robots (orange references in Figure~\ref{fig:circumplex}), we noticed that most tasks are located in the \textit{performance} octant. The papers reviewed in this category discuss the perceptions people had seeing groups of robots executing a certain task, or videos of those performances, without requiring any human intervention. Therefore, it is hard to assess a specific role for robots in those situations. Nonetheless, as mere performers, such as the vacuum cleaner or the robotic trash bin, they can be seen as servants or subordinates.

Finally, the papers within the category of group behaviour cover several types of tasks (green references in Figure~\ref{fig:circumplex}), including the uncommon creative type. Interestingly, we noticed a trend in the role of the robot(s) in this set of papers, which is a mediator or a facilitator.
When the robot mediates or facilitates the interaction, its goal is somehow complementary to the humans and, therefore, it is strong enough to influence and shape the interaction.


\subsubsection{Expected contributions}

Figure~\ref{fig:circumplex-contributions} revisits the circumplex of group tasks and adds the expected contributions of this dissertation. The \textit{contribution A}, which is detailed in Chapter~\ref{chapter:membership-formation}, explores group formation, membership preferences, and perceptions of robotic teammates in a decision making task. Secondly, \textit{contribution B}, detailed in Chapter~\ref{chapter:pro-sociality}, explores the perceptions of robotic teammates that favour different interests in a mixed motive task. \textit{Contribution C}, presented in Chapter~\ref{chapter:group-based-emotions}, adds to the literature of group behaviour by exploring the generation of group-based emotions in robotic teammates during a decision making task. Finally, \textit{contribution D}, which is the future work of this ongoing dissertation and detailed in Chapter~\ref{chapter:future-work}, aims at contributing as well to group behaviour, but in a mixed motive task.

\begin{figure}
    \centering
    \input{images/related-work/circumplex-contributions.tex}
    \caption{Expected contributions of this dissertation in the Circumplex of Group Tasks \cite{mcgrath1995methodology}}
    \label{fig:circumplex-contributions}
\end{figure}




%One crucial factor that is needed to enable successful teamwork is a sense of group trust \cite{Jones1998,Ma2018}. This has led roboticists to explore and find different types of behaviours that robotic teammates can perform to increase how much people trust them. For instance, having a robot making vulnerable statements has been found to increase the amount of trust-related behaviours from its human partners. Such effect was discovered in a study conducted with a team of three individuals playing a collaborative digital game with a NAO robot \cite{StrohkorbSebo2018}. In the study, the robot expresses vulnerability by admitting its mistakes to the group, which increases the amount of times that people will also admit to their mistakes.

